{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "LO0eHv13yNps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "7vJQeDvYdwU4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grFzJH6PZEa2"
      },
      "source": [
        "# Building ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "RqFaap3HZEa4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=100):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isacvmMmgmjA",
        "outputId": "c4ccfc2c-a63f-435f-ecad-5712724a22ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "batch_size = 64\n",
        "model = ResNet18()\n",
        "summary(model, input_size=(batch_size, 3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIFrQX5XdVRv",
        "outputId": "02844c19-f15e-4b69-eb54-7c839d0cd4cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet                                   [64, 100]                 --\n",
              "├─Conv2d: 1-1                            [64, 64, 32, 32]          1,728\n",
              "├─BatchNorm2d: 1-2                       [64, 64, 32, 32]          128\n",
              "├─Sequential: 1-3                        [64, 64, 32, 32]          --\n",
              "│    └─BasicBlock: 2-1                   [64, 64, 32, 32]          --\n",
              "│    │    └─Conv2d: 3-1                  [64, 64, 32, 32]          36,864\n",
              "│    │    └─BatchNorm2d: 3-2             [64, 64, 32, 32]          128\n",
              "│    │    └─Conv2d: 3-3                  [64, 64, 32, 32]          36,864\n",
              "│    │    └─BatchNorm2d: 3-4             [64, 64, 32, 32]          128\n",
              "│    │    └─Sequential: 3-5              [64, 64, 32, 32]          --\n",
              "│    └─BasicBlock: 2-2                   [64, 64, 32, 32]          --\n",
              "│    │    └─Conv2d: 3-6                  [64, 64, 32, 32]          36,864\n",
              "│    │    └─BatchNorm2d: 3-7             [64, 64, 32, 32]          128\n",
              "│    │    └─Conv2d: 3-8                  [64, 64, 32, 32]          36,864\n",
              "│    │    └─BatchNorm2d: 3-9             [64, 64, 32, 32]          128\n",
              "│    │    └─Sequential: 3-10             [64, 64, 32, 32]          --\n",
              "├─Sequential: 1-4                        [64, 128, 16, 16]         --\n",
              "│    └─BasicBlock: 2-3                   [64, 128, 16, 16]         --\n",
              "│    │    └─Conv2d: 3-11                 [64, 128, 16, 16]         73,728\n",
              "│    │    └─BatchNorm2d: 3-12            [64, 128, 16, 16]         256\n",
              "│    │    └─Conv2d: 3-13                 [64, 128, 16, 16]         147,456\n",
              "│    │    └─BatchNorm2d: 3-14            [64, 128, 16, 16]         256\n",
              "│    │    └─Sequential: 3-15             [64, 128, 16, 16]         8,448\n",
              "│    └─BasicBlock: 2-4                   [64, 128, 16, 16]         --\n",
              "│    │    └─Conv2d: 3-16                 [64, 128, 16, 16]         147,456\n",
              "│    │    └─BatchNorm2d: 3-17            [64, 128, 16, 16]         256\n",
              "│    │    └─Conv2d: 3-18                 [64, 128, 16, 16]         147,456\n",
              "│    │    └─BatchNorm2d: 3-19            [64, 128, 16, 16]         256\n",
              "│    │    └─Sequential: 3-20             [64, 128, 16, 16]         --\n",
              "├─Sequential: 1-5                        [64, 256, 8, 8]           --\n",
              "│    └─BasicBlock: 2-5                   [64, 256, 8, 8]           --\n",
              "│    │    └─Conv2d: 3-21                 [64, 256, 8, 8]           294,912\n",
              "│    │    └─BatchNorm2d: 3-22            [64, 256, 8, 8]           512\n",
              "│    │    └─Conv2d: 3-23                 [64, 256, 8, 8]           589,824\n",
              "│    │    └─BatchNorm2d: 3-24            [64, 256, 8, 8]           512\n",
              "│    │    └─Sequential: 3-25             [64, 256, 8, 8]           33,280\n",
              "│    └─BasicBlock: 2-6                   [64, 256, 8, 8]           --\n",
              "│    │    └─Conv2d: 3-26                 [64, 256, 8, 8]           589,824\n",
              "│    │    └─BatchNorm2d: 3-27            [64, 256, 8, 8]           512\n",
              "│    │    └─Conv2d: 3-28                 [64, 256, 8, 8]           589,824\n",
              "│    │    └─BatchNorm2d: 3-29            [64, 256, 8, 8]           512\n",
              "│    │    └─Sequential: 3-30             [64, 256, 8, 8]           --\n",
              "├─Sequential: 1-6                        [64, 512, 4, 4]           --\n",
              "│    └─BasicBlock: 2-7                   [64, 512, 4, 4]           --\n",
              "│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           1,179,648\n",
              "│    │    └─BatchNorm2d: 3-32            [64, 512, 4, 4]           1,024\n",
              "│    │    └─Conv2d: 3-33                 [64, 512, 4, 4]           2,359,296\n",
              "│    │    └─BatchNorm2d: 3-34            [64, 512, 4, 4]           1,024\n",
              "│    │    └─Sequential: 3-35             [64, 512, 4, 4]           132,096\n",
              "│    └─BasicBlock: 2-8                   [64, 512, 4, 4]           --\n",
              "│    │    └─Conv2d: 3-36                 [64, 512, 4, 4]           2,359,296\n",
              "│    │    └─BatchNorm2d: 3-37            [64, 512, 4, 4]           1,024\n",
              "│    │    └─Conv2d: 3-38                 [64, 512, 4, 4]           2,359,296\n",
              "│    │    └─BatchNorm2d: 3-39            [64, 512, 4, 4]           1,024\n",
              "│    │    └─Sequential: 3-40             [64, 512, 4, 4]           --\n",
              "├─Linear: 1-7                            [64, 100]                 51,300\n",
              "==========================================================================================\n",
              "Total params: 11,220,132\n",
              "Trainable params: 11,220,132\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 35.55\n",
              "==========================================================================================\n",
              "Input size (MB): 0.79\n",
              "Forward/backward pass size (MB): 629.20\n",
              "Params size (MB): 44.88\n",
              "Estimated Total Size (MB): 674.86\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables separately\n",
        "batch_size = 128\n",
        "test_batch_size = 128\n",
        "epochs = 150\n",
        "weight_decay = 2e-4\n",
        "lr = 0.1\n",
        "momentum = 0.9\n",
        "no_cuda = False\n",
        "seed = 1\n",
        "model_dir = './model-cifar100'\n",
        "\n",
        "# Settings\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "torch.manual_seed(seed)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
      ],
      "metadata": {
        "id": "V94T0pzfdzEO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data loader for CIFAR-100\n",
        "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),])\n",
        "\n",
        "transform_test = transforms.Compose([transforms.ToTensor(),])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='../data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR100(root='../data', train=False, download=True, transform=transform_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X4nhkHzeCLq",
        "outputId": "3c2df3ef-114a-46d4-8b05-455b23880c3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ../data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:12<00:00, 13167430.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/cifar-100-python.tar.gz to ../data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train function\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate loss\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluation functions for train and test data\n",
        "def eval_model(model, device, data_loader, loader_type, epoch):\n",
        "    assert loader_type in ['train', 'test'], \"loader_type must be either 'train' or 'test'\"\n",
        "    model.eval()\n",
        "    data_loss = 0\n",
        "    correct = 0\n",
        "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            data_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    data_loss /= len(data_loader.dataset)\n",
        "\n",
        "    print('Epoch: {}, {}: Average loss: {:.4f}, Accuracy: {:.0f}%'.format(epoch, \n",
        "                                                                          loader_type.capitalize(), \n",
        "                                                                          data_loss,\n",
        "                                                                          100. * correct / len(data_loader.dataset)))\n",
        "\n",
        "    data_accuracy = correct / len(data_loader.dataset)\n",
        "    return data_loss, data_accuracy"
      ],
      "metadata": {
        "id": "eOnaoxW6hdhL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust learning rate function\n",
        "def adjust_learning_rate(optimizer, epoch, initial_lr):\n",
        "    lr = initial_lr\n",
        "    if epoch >= 75:\n",
        "        lr = initial_lr * 0.1\n",
        "    if epoch >= 90:\n",
        "        lr = initial_lr * 0.01\n",
        "    if epoch >= 100:\n",
        "        lr = initial_lr * 0.001\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "metadata": {
        "id": "ok1lVXo4ho84"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnI2sZbEZEa7",
        "outputId": "72cac5d2-69aa-4986-9e3b-927846ca0318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on CIFAR100 dataset\n",
            "================================================================\n",
            "Epoch: 1, Train: Average loss: 3.9235, Accuracy: 10%\n",
            "epoch: 1\n",
            "train_losses: 3.9235494787597656\n",
            "train_accuracy: 0.09808\n",
            "Epoch: 1, Test: Average loss: 3.9197, Accuracy: 10%\n",
            "================================================================\n",
            "Epoch: 2, Train: Average loss: 3.3037, Accuracy: 20%\n",
            "epoch: 2\n",
            "train_losses: 3.3037192343139647\n",
            "train_accuracy: 0.1966\n",
            "Epoch: 2, Test: Average loss: 3.3322, Accuracy: 20%\n",
            "================================================================\n",
            "Epoch: 3, Train: Average loss: 3.0879, Accuracy: 23%\n",
            "epoch: 3\n",
            "train_losses: 3.087922897338867\n",
            "train_accuracy: 0.22922\n",
            "Epoch: 3, Test: Average loss: 3.1732, Accuracy: 23%\n",
            "================================================================\n",
            "Epoch: 4, Train: Average loss: 2.5059, Accuracy: 35%\n",
            "epoch: 4\n",
            "train_losses: 2.505856487121582\n",
            "train_accuracy: 0.34776\n",
            "Epoch: 4, Test: Average loss: 2.5599, Accuracy: 34%\n",
            "================================================================\n",
            "Epoch: 5, Train: Average loss: 2.0577, Accuracy: 44%\n",
            "epoch: 5\n",
            "train_losses: 2.057650827636719\n",
            "train_accuracy: 0.44398\n",
            "Epoch: 5, Test: Average loss: 2.1715, Accuracy: 43%\n",
            "================================================================\n",
            "Epoch: 6, Train: Average loss: 1.9501, Accuracy: 47%\n",
            "epoch: 6\n",
            "train_losses: 1.9501251931762695\n",
            "train_accuracy: 0.4671\n",
            "Epoch: 6, Test: Average loss: 2.1508, Accuracy: 44%\n",
            "================================================================\n",
            "Epoch: 7, Train: Average loss: 1.6271, Accuracy: 54%\n",
            "epoch: 7\n",
            "train_losses: 1.6270929795837403\n",
            "train_accuracy: 0.53636\n",
            "Epoch: 7, Test: Average loss: 1.7840, Accuracy: 51%\n",
            "================================================================\n",
            "Epoch: 8, Train: Average loss: 1.4530, Accuracy: 59%\n",
            "epoch: 8\n",
            "train_losses: 1.4530075135803222\n",
            "train_accuracy: 0.58578\n",
            "Epoch: 8, Test: Average loss: 1.6993, Accuracy: 53%\n",
            "================================================================\n",
            "Epoch: 9, Train: Average loss: 1.3913, Accuracy: 60%\n",
            "epoch: 9\n",
            "train_losses: 1.3913059776306151\n",
            "train_accuracy: 0.60104\n",
            "Epoch: 9, Test: Average loss: 1.7074, Accuracy: 54%\n",
            "================================================================\n",
            "Epoch: 10, Train: Average loss: 1.3821, Accuracy: 60%\n",
            "epoch: 10\n",
            "train_losses: 1.3820694589233398\n",
            "train_accuracy: 0.60012\n",
            "Epoch: 10, Test: Average loss: 1.6917, Accuracy: 54%\n",
            "================================================================\n",
            "Epoch: 11, Train: Average loss: 1.3244, Accuracy: 61%\n",
            "epoch: 11\n",
            "train_losses: 1.324376639251709\n",
            "train_accuracy: 0.61172\n",
            "Epoch: 11, Test: Average loss: 1.6707, Accuracy: 54%\n",
            "================================================================\n",
            "Epoch: 12, Train: Average loss: 1.1667, Accuracy: 65%\n",
            "epoch: 12\n",
            "train_losses: 1.1666997952270508\n",
            "train_accuracy: 0.65012\n",
            "Epoch: 12, Test: Average loss: 1.5705, Accuracy: 58%\n",
            "================================================================\n",
            "Epoch: 13, Train: Average loss: 1.1081, Accuracy: 67%\n",
            "epoch: 13\n",
            "train_losses: 1.1081084063720703\n",
            "train_accuracy: 0.6691\n",
            "Epoch: 13, Test: Average loss: 1.5685, Accuracy: 58%\n",
            "================================================================\n",
            "Epoch: 14, Train: Average loss: 1.0172, Accuracy: 70%\n",
            "epoch: 14\n",
            "train_losses: 1.0172219400024414\n",
            "train_accuracy: 0.69526\n",
            "Epoch: 14, Test: Average loss: 1.4615, Accuracy: 60%\n",
            "================================================================\n",
            "Epoch: 15, Train: Average loss: 1.0927, Accuracy: 67%\n",
            "epoch: 15\n",
            "train_losses: 1.0926812191772461\n",
            "train_accuracy: 0.67316\n",
            "Epoch: 15, Test: Average loss: 1.6003, Accuracy: 58%\n",
            "================================================================\n",
            "Epoch: 16, Train: Average loss: 1.1664, Accuracy: 66%\n",
            "epoch: 16\n",
            "train_losses: 1.166377244873047\n",
            "train_accuracy: 0.66094\n",
            "Epoch: 16, Test: Average loss: 1.6858, Accuracy: 57%\n",
            "================================================================\n",
            "Epoch: 17, Train: Average loss: 1.1057, Accuracy: 68%\n",
            "epoch: 17\n",
            "train_losses: 1.1056570442199707\n",
            "train_accuracy: 0.67696\n",
            "Epoch: 17, Test: Average loss: 1.6675, Accuracy: 58%\n",
            "================================================================\n",
            "Epoch: 18, Train: Average loss: 0.9923, Accuracy: 70%\n",
            "epoch: 18\n",
            "train_losses: 0.9922935028839112\n",
            "train_accuracy: 0.7037\n",
            "Epoch: 18, Test: Average loss: 1.5646, Accuracy: 59%\n",
            "================================================================\n",
            "Epoch: 19, Train: Average loss: 0.9254, Accuracy: 72%\n",
            "epoch: 19\n",
            "train_losses: 0.9253666529846192\n",
            "train_accuracy: 0.72364\n",
            "Epoch: 19, Test: Average loss: 1.5325, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 20, Train: Average loss: 0.8866, Accuracy: 73%\n",
            "epoch: 20\n",
            "train_losses: 0.8865671244812011\n",
            "train_accuracy: 0.73238\n",
            "Epoch: 20, Test: Average loss: 1.4564, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 21, Train: Average loss: 0.8026, Accuracy: 75%\n",
            "epoch: 21\n",
            "train_losses: 0.802580101928711\n",
            "train_accuracy: 0.75314\n",
            "Epoch: 21, Test: Average loss: 1.4352, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 22, Train: Average loss: 0.8145, Accuracy: 75%\n",
            "epoch: 22\n",
            "train_losses: 0.8144813801574707\n",
            "train_accuracy: 0.75182\n",
            "Epoch: 22, Test: Average loss: 1.4700, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 23, Train: Average loss: 0.7681, Accuracy: 77%\n",
            "epoch: 23\n",
            "train_losses: 0.7680967057800293\n",
            "train_accuracy: 0.76506\n",
            "Epoch: 23, Test: Average loss: 1.4773, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 24, Train: Average loss: 0.8330, Accuracy: 75%\n",
            "epoch: 24\n",
            "train_losses: 0.8330346383666992\n",
            "train_accuracy: 0.7471\n",
            "Epoch: 24, Test: Average loss: 1.5490, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 25, Train: Average loss: 0.8174, Accuracy: 75%\n",
            "epoch: 25\n",
            "train_losses: 0.8174067720031738\n",
            "train_accuracy: 0.74912\n",
            "Epoch: 25, Test: Average loss: 1.5715, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 26, Train: Average loss: 0.9350, Accuracy: 72%\n",
            "epoch: 26\n",
            "train_losses: 0.9349540382385254\n",
            "train_accuracy: 0.71802\n",
            "Epoch: 26, Test: Average loss: 1.6779, Accuracy: 58%\n",
            "================================================================\n",
            "Epoch: 27, Train: Average loss: 0.6670, Accuracy: 79%\n",
            "epoch: 27\n",
            "train_losses: 0.666978275680542\n",
            "train_accuracy: 0.79208\n",
            "Epoch: 27, Test: Average loss: 1.4802, Accuracy: 63%\n",
            "================================================================\n",
            "Epoch: 28, Train: Average loss: 0.7299, Accuracy: 77%\n",
            "epoch: 28\n",
            "train_losses: 0.7299398935699463\n",
            "train_accuracy: 0.77472\n",
            "Epoch: 28, Test: Average loss: 1.4984, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 29, Train: Average loss: 0.6887, Accuracy: 79%\n",
            "epoch: 29\n",
            "train_losses: 0.6887463056182861\n",
            "train_accuracy: 0.78536\n",
            "Epoch: 29, Test: Average loss: 1.4914, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 30, Train: Average loss: 0.6733, Accuracy: 79%\n",
            "epoch: 30\n",
            "train_losses: 0.6733204339599609\n",
            "train_accuracy: 0.79036\n",
            "Epoch: 30, Test: Average loss: 1.5181, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 31, Train: Average loss: 0.6809, Accuracy: 79%\n",
            "epoch: 31\n",
            "train_losses: 0.6808505124664307\n",
            "train_accuracy: 0.79042\n",
            "Epoch: 31, Test: Average loss: 1.5755, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 32, Train: Average loss: 0.7472, Accuracy: 77%\n",
            "epoch: 32\n",
            "train_losses: 0.747157333908081\n",
            "train_accuracy: 0.77272\n",
            "Epoch: 32, Test: Average loss: 1.6245, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 33, Train: Average loss: 0.7538, Accuracy: 77%\n",
            "epoch: 33\n",
            "train_losses: 0.7538274262237549\n",
            "train_accuracy: 0.77018\n",
            "Epoch: 33, Test: Average loss: 1.6782, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 34, Train: Average loss: 0.7950, Accuracy: 76%\n",
            "epoch: 34\n",
            "train_losses: 0.7949687300872803\n",
            "train_accuracy: 0.75722\n",
            "Epoch: 34, Test: Average loss: 1.6139, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 35, Train: Average loss: 0.6999, Accuracy: 78%\n",
            "epoch: 35\n",
            "train_losses: 0.6998581205749512\n",
            "train_accuracy: 0.7827\n",
            "Epoch: 35, Test: Average loss: 1.5788, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 36, Train: Average loss: 0.8440, Accuracy: 75%\n",
            "epoch: 36\n",
            "train_losses: 0.8439648567199707\n",
            "train_accuracy: 0.74932\n",
            "Epoch: 36, Test: Average loss: 1.7803, Accuracy: 59%\n",
            "================================================================\n",
            "Epoch: 37, Train: Average loss: 0.8136, Accuracy: 75%\n",
            "epoch: 37\n",
            "train_losses: 0.8135730419921875\n",
            "train_accuracy: 0.74952\n",
            "Epoch: 37, Test: Average loss: 1.6941, Accuracy: 60%\n",
            "================================================================\n",
            "Epoch: 38, Train: Average loss: 0.7145, Accuracy: 78%\n",
            "epoch: 38\n",
            "train_losses: 0.7144992852020263\n",
            "train_accuracy: 0.78112\n",
            "Epoch: 38, Test: Average loss: 1.7347, Accuracy: 60%\n",
            "================================================================\n",
            "Epoch: 39, Train: Average loss: 0.6838, Accuracy: 79%\n",
            "epoch: 39\n",
            "train_losses: 0.6837767269897461\n",
            "train_accuracy: 0.78846\n",
            "Epoch: 39, Test: Average loss: 1.6789, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 40, Train: Average loss: 0.7575, Accuracy: 77%\n",
            "epoch: 40\n",
            "train_losses: 0.7575008174133301\n",
            "train_accuracy: 0.7692\n",
            "Epoch: 40, Test: Average loss: 1.6954, Accuracy: 60%\n",
            "================================================================\n",
            "Epoch: 41, Train: Average loss: 0.6751, Accuracy: 79%\n",
            "epoch: 41\n",
            "train_losses: 0.6751257427978515\n",
            "train_accuracy: 0.78748\n",
            "Epoch: 41, Test: Average loss: 1.6332, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 42, Train: Average loss: 0.7014, Accuracy: 79%\n",
            "epoch: 42\n",
            "train_losses: 0.7013972143554688\n",
            "train_accuracy: 0.78792\n",
            "Epoch: 42, Test: Average loss: 1.6909, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 43, Train: Average loss: 0.9010, Accuracy: 74%\n",
            "epoch: 43\n",
            "train_losses: 0.9009980189514161\n",
            "train_accuracy: 0.74002\n",
            "Epoch: 43, Test: Average loss: 1.8836, Accuracy: 58%\n",
            "================================================================\n",
            "Epoch: 44, Train: Average loss: 0.5711, Accuracy: 82%\n",
            "epoch: 44\n",
            "train_losses: 0.5710777796173095\n",
            "train_accuracy: 0.82144\n",
            "Epoch: 44, Test: Average loss: 1.5446, Accuracy: 63%\n",
            "================================================================\n",
            "Epoch: 45, Train: Average loss: 0.6188, Accuracy: 81%\n",
            "epoch: 45\n",
            "train_losses: 0.6187827690124512\n",
            "train_accuracy: 0.81042\n",
            "Epoch: 45, Test: Average loss: 1.6191, Accuracy: 63%\n",
            "================================================================\n",
            "Epoch: 46, Train: Average loss: 0.6143, Accuracy: 81%\n",
            "epoch: 46\n",
            "train_losses: 0.6143281429290771\n",
            "train_accuracy: 0.80902\n",
            "Epoch: 46, Test: Average loss: 1.6360, Accuracy: 63%\n",
            "================================================================\n",
            "Epoch: 47, Train: Average loss: 0.5678, Accuracy: 82%\n",
            "epoch: 47\n",
            "train_losses: 0.5678191182708741\n",
            "train_accuracy: 0.82382\n",
            "Epoch: 47, Test: Average loss: 1.6165, Accuracy: 64%\n",
            "================================================================\n",
            "Epoch: 48, Train: Average loss: 0.6960, Accuracy: 79%\n",
            "epoch: 48\n",
            "train_losses: 0.6960130457305909\n",
            "train_accuracy: 0.78628\n",
            "Epoch: 48, Test: Average loss: 1.7194, Accuracy: 60%\n",
            "================================================================\n",
            "Epoch: 49, Train: Average loss: 0.7591, Accuracy: 77%\n",
            "epoch: 49\n",
            "train_losses: 0.7590792220306396\n",
            "train_accuracy: 0.77206\n",
            "Epoch: 49, Test: Average loss: 1.8133, Accuracy: 60%\n",
            "================================================================\n",
            "Epoch: 50, Train: Average loss: 0.6331, Accuracy: 81%\n",
            "epoch: 50\n",
            "train_losses: 0.6330823832702637\n",
            "train_accuracy: 0.80526\n",
            "Epoch: 50, Test: Average loss: 1.6344, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 51, Train: Average loss: 0.5722, Accuracy: 82%\n",
            "epoch: 51\n",
            "train_losses: 0.5721790163421631\n",
            "train_accuracy: 0.8231\n",
            "Epoch: 51, Test: Average loss: 1.5775, Accuracy: 63%\n",
            "================================================================\n",
            "Epoch: 52, Train: Average loss: 0.5823, Accuracy: 82%\n",
            "epoch: 52\n",
            "train_losses: 0.5823096561431885\n",
            "train_accuracy: 0.81828\n",
            "Epoch: 52, Test: Average loss: 1.5504, Accuracy: 63%\n",
            "================================================================\n",
            "Epoch: 53, Train: Average loss: 0.5836, Accuracy: 82%\n",
            "epoch: 53\n",
            "train_losses: 0.5835737174987793\n",
            "train_accuracy: 0.81804\n",
            "Epoch: 53, Test: Average loss: 1.6944, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 54, Train: Average loss: 0.6734, Accuracy: 79%\n",
            "epoch: 54\n",
            "train_losses: 0.6733988120269775\n",
            "train_accuracy: 0.79218\n",
            "Epoch: 54, Test: Average loss: 1.7081, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 55, Train: Average loss: 0.4825, Accuracy: 85%\n",
            "epoch: 55\n",
            "train_losses: 0.48249601318359375\n",
            "train_accuracy: 0.84774\n",
            "Epoch: 55, Test: Average loss: 1.5055, Accuracy: 64%\n",
            "================================================================\n",
            "Epoch: 56, Train: Average loss: 0.6156, Accuracy: 81%\n",
            "epoch: 56\n",
            "train_losses: 0.6155691873550415\n",
            "train_accuracy: 0.81178\n",
            "Epoch: 56, Test: Average loss: 1.6504, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 57, Train: Average loss: 0.6297, Accuracy: 81%\n",
            "epoch: 57\n",
            "train_losses: 0.629654395980835\n",
            "train_accuracy: 0.80736\n",
            "Epoch: 57, Test: Average loss: 1.6495, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 58, Train: Average loss: 0.5617, Accuracy: 83%\n",
            "epoch: 58\n",
            "train_losses: 0.5617210733795166\n",
            "train_accuracy: 0.82632\n",
            "Epoch: 58, Test: Average loss: 1.5753, Accuracy: 63%\n",
            "================================================================\n",
            "Epoch: 59, Train: Average loss: 0.5748, Accuracy: 82%\n",
            "epoch: 59\n",
            "train_losses: 0.5748278903198242\n",
            "train_accuracy: 0.82496\n",
            "Epoch: 59, Test: Average loss: 1.5886, Accuracy: 63%\n",
            "================================================================\n",
            "Epoch: 60, Train: Average loss: 0.5878, Accuracy: 82%\n",
            "epoch: 60\n",
            "train_losses: 0.5877965682983398\n",
            "train_accuracy: 0.82136\n",
            "Epoch: 60, Test: Average loss: 1.6842, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 61, Train: Average loss: 0.6375, Accuracy: 81%\n",
            "epoch: 61\n",
            "train_losses: 0.6374952393341065\n",
            "train_accuracy: 0.80512\n",
            "Epoch: 61, Test: Average loss: 1.7168, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 62, Train: Average loss: 0.6637, Accuracy: 80%\n",
            "epoch: 62\n",
            "train_losses: 0.6637088211059571\n",
            "train_accuracy: 0.79652\n",
            "Epoch: 62, Test: Average loss: 1.7509, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 63, Train: Average loss: 0.6257, Accuracy: 81%\n",
            "epoch: 63\n",
            "train_losses: 0.625731661529541\n",
            "train_accuracy: 0.80884\n",
            "Epoch: 63, Test: Average loss: 1.6811, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 64, Train: Average loss: 0.5861, Accuracy: 82%\n",
            "epoch: 64\n",
            "train_losses: 0.5860752397155762\n",
            "train_accuracy: 0.81834\n",
            "Epoch: 64, Test: Average loss: 1.6335, Accuracy: 63%\n",
            "================================================================\n",
            "Epoch: 65, Train: Average loss: 0.5348, Accuracy: 83%\n",
            "epoch: 65\n",
            "train_losses: 0.5348027746582031\n",
            "train_accuracy: 0.83268\n",
            "Epoch: 65, Test: Average loss: 1.6005, Accuracy: 63%\n",
            "================================================================\n",
            "Epoch: 66, Train: Average loss: 0.6225, Accuracy: 81%\n",
            "epoch: 66\n",
            "train_losses: 0.6225454725646973\n",
            "train_accuracy: 0.80834\n",
            "Epoch: 66, Test: Average loss: 1.6657, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 67, Train: Average loss: 0.6000, Accuracy: 81%\n",
            "epoch: 67\n",
            "train_losses: 0.6000314755249023\n",
            "train_accuracy: 0.81474\n",
            "Epoch: 67, Test: Average loss: 1.6512, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 68, Train: Average loss: 0.5911, Accuracy: 82%\n",
            "epoch: 68\n",
            "train_losses: 0.5910761717224121\n",
            "train_accuracy: 0.8158\n",
            "Epoch: 68, Test: Average loss: 1.6616, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 69, Train: Average loss: 0.6243, Accuracy: 81%\n",
            "epoch: 69\n",
            "train_losses: 0.6243263325500489\n",
            "train_accuracy: 0.80692\n",
            "Epoch: 69, Test: Average loss: 1.7147, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 70, Train: Average loss: 0.5848, Accuracy: 82%\n",
            "epoch: 70\n",
            "train_losses: 0.5847988043212891\n",
            "train_accuracy: 0.81886\n",
            "Epoch: 70, Test: Average loss: 1.6620, Accuracy: 62%\n",
            "================================================================\n",
            "Epoch: 71, Train: Average loss: 0.6219, Accuracy: 81%\n",
            "epoch: 71\n",
            "train_losses: 0.6218731453704834\n",
            "train_accuracy: 0.81068\n",
            "Epoch: 71, Test: Average loss: 1.7988, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 72, Train: Average loss: 0.8500, Accuracy: 75%\n",
            "epoch: 72\n",
            "train_losses: 0.8500475196838378\n",
            "train_accuracy: 0.7476\n",
            "Epoch: 72, Test: Average loss: 1.9014, Accuracy: 57%\n",
            "================================================================\n",
            "Epoch: 73, Train: Average loss: 0.6798, Accuracy: 79%\n",
            "epoch: 73\n",
            "train_losses: 0.679849298171997\n",
            "train_accuracy: 0.7908\n",
            "Epoch: 73, Test: Average loss: 1.7415, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 74, Train: Average loss: 0.6311, Accuracy: 80%\n",
            "epoch: 74\n",
            "train_losses: 0.6310613015747071\n",
            "train_accuracy: 0.80382\n",
            "Epoch: 74, Test: Average loss: 1.7526, Accuracy: 61%\n",
            "================================================================\n",
            "Epoch: 75, Train: Average loss: 0.0964, Accuracy: 98%\n",
            "epoch: 75\n",
            "train_losses: 0.09642139895439147\n",
            "train_accuracy: 0.9764\n",
            "Epoch: 75, Test: Average loss: 1.0837, Accuracy: 73%\n",
            "================================================================\n",
            "Epoch: 76, Train: Average loss: 0.0678, Accuracy: 99%\n",
            "epoch: 76\n",
            "train_losses: 0.06782245272636414\n",
            "train_accuracy: 0.98612\n",
            "Epoch: 76, Test: Average loss: 1.0653, Accuracy: 74%\n",
            "================================================================\n",
            "Epoch: 77, Train: Average loss: 0.0545, Accuracy: 99%\n",
            "epoch: 77\n",
            "train_losses: 0.054540573930740355\n",
            "train_accuracy: 0.98948\n",
            "Epoch: 77, Test: Average loss: 1.0647, Accuracy: 74%\n",
            "================================================================\n",
            "Epoch: 78, Train: Average loss: 0.0442, Accuracy: 99%\n",
            "epoch: 78\n",
            "train_losses: 0.04419198920726776\n",
            "train_accuracy: 0.99232\n",
            "Epoch: 78, Test: Average loss: 1.0732, Accuracy: 74%\n",
            "================================================================\n",
            "Epoch: 79, Train: Average loss: 0.0382, Accuracy: 99%\n",
            "epoch: 79\n",
            "train_losses: 0.03823750168323517\n",
            "train_accuracy: 0.99378\n",
            "Epoch: 79, Test: Average loss: 1.0771, Accuracy: 74%\n",
            "================================================================\n",
            "Epoch: 80, Train: Average loss: 0.0327, Accuracy: 100%\n",
            "epoch: 80\n",
            "train_losses: 0.03271225413322449\n",
            "train_accuracy: 0.99528\n",
            "Epoch: 80, Test: Average loss: 1.0792, Accuracy: 74%\n",
            "================================================================\n",
            "Epoch: 81, Train: Average loss: 0.0295, Accuracy: 100%\n",
            "epoch: 81\n",
            "train_losses: 0.029495185420513152\n",
            "train_accuracy: 0.99634\n",
            "Epoch: 81, Test: Average loss: 1.0774, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 82, Train: Average loss: 0.0257, Accuracy: 100%\n",
            "epoch: 82\n",
            "train_losses: 0.025739228012561798\n",
            "train_accuracy: 0.9968\n",
            "Epoch: 82, Test: Average loss: 1.0859, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 83, Train: Average loss: 0.0240, Accuracy: 100%\n",
            "epoch: 83\n",
            "train_losses: 0.024032640640735625\n",
            "train_accuracy: 0.99668\n",
            "Epoch: 83, Test: Average loss: 1.0861, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 84, Train: Average loss: 0.0214, Accuracy: 100%\n",
            "epoch: 84\n",
            "train_losses: 0.02137455342888832\n",
            "train_accuracy: 0.99766\n",
            "Epoch: 84, Test: Average loss: 1.0895, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 85, Train: Average loss: 0.0203, Accuracy: 100%\n",
            "epoch: 85\n",
            "train_losses: 0.020315452498197554\n",
            "train_accuracy: 0.99756\n",
            "Epoch: 85, Test: Average loss: 1.0882, Accuracy: 74%\n",
            "================================================================\n",
            "Epoch: 86, Train: Average loss: 0.0186, Accuracy: 100%\n",
            "epoch: 86\n",
            "train_losses: 0.018609578969478607\n",
            "train_accuracy: 0.99792\n",
            "Epoch: 86, Test: Average loss: 1.0879, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 87, Train: Average loss: 0.0181, Accuracy: 100%\n",
            "epoch: 87\n",
            "train_losses: 0.018144332178831102\n",
            "train_accuracy: 0.99806\n",
            "Epoch: 87, Test: Average loss: 1.0799, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 88, Train: Average loss: 0.0168, Accuracy: 100%\n",
            "epoch: 88\n",
            "train_losses: 0.01675434633731842\n",
            "train_accuracy: 0.99816\n",
            "Epoch: 88, Test: Average loss: 1.0868, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 89, Train: Average loss: 0.0153, Accuracy: 100%\n",
            "epoch: 89\n",
            "train_losses: 0.015325830154418945\n",
            "train_accuracy: 0.99868\n",
            "Epoch: 89, Test: Average loss: 1.0929, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 90, Train: Average loss: 0.0150, Accuracy: 100%\n",
            "epoch: 90\n",
            "train_losses: 0.01499543523669243\n",
            "train_accuracy: 0.99894\n",
            "Epoch: 90, Test: Average loss: 1.0889, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 91, Train: Average loss: 0.0151, Accuracy: 100%\n",
            "epoch: 91\n",
            "train_losses: 0.015143836126327515\n",
            "train_accuracy: 0.9987\n",
            "Epoch: 91, Test: Average loss: 1.0871, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 92, Train: Average loss: 0.0146, Accuracy: 100%\n",
            "epoch: 92\n",
            "train_losses: 0.014603066897392273\n",
            "train_accuracy: 0.99898\n",
            "Epoch: 92, Test: Average loss: 1.0869, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 93, Train: Average loss: 0.0144, Accuracy: 100%\n",
            "epoch: 93\n",
            "train_losses: 0.014443659760951995\n",
            "train_accuracy: 0.99888\n",
            "Epoch: 93, Test: Average loss: 1.0893, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 94, Train: Average loss: 0.0144, Accuracy: 100%\n",
            "epoch: 94\n",
            "train_losses: 0.014399568059444428\n",
            "train_accuracy: 0.99882\n",
            "Epoch: 94, Test: Average loss: 1.0871, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 95, Train: Average loss: 0.0148, Accuracy: 100%\n",
            "epoch: 95\n",
            "train_losses: 0.014798427649736405\n",
            "train_accuracy: 0.9988\n",
            "Epoch: 95, Test: Average loss: 1.0851, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 96, Train: Average loss: 0.0145, Accuracy: 100%\n",
            "epoch: 96\n",
            "train_losses: 0.014479373381137847\n",
            "train_accuracy: 0.99894\n",
            "Epoch: 96, Test: Average loss: 1.0876, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 97, Train: Average loss: 0.0141, Accuracy: 100%\n",
            "epoch: 97\n",
            "train_losses: 0.014085386010408402\n",
            "train_accuracy: 0.99886\n",
            "Epoch: 97, Test: Average loss: 1.0881, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 98, Train: Average loss: 0.0141, Accuracy: 100%\n",
            "epoch: 98\n",
            "train_losses: 0.014108391783237457\n",
            "train_accuracy: 0.99878\n",
            "Epoch: 98, Test: Average loss: 1.0839, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 99, Train: Average loss: 0.0139, Accuracy: 100%\n",
            "epoch: 99\n",
            "train_losses: 0.013869912937879562\n",
            "train_accuracy: 0.99896\n",
            "Epoch: 99, Test: Average loss: 1.0838, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 100, Train: Average loss: 0.0133, Accuracy: 100%\n",
            "epoch: 100\n",
            "train_losses: 0.013299473515748977\n",
            "train_accuracy: 0.999\n",
            "Epoch: 100, Test: Average loss: 1.0872, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 101, Train: Average loss: 0.0138, Accuracy: 100%\n",
            "epoch: 101\n",
            "train_losses: 0.013786897710561753\n",
            "train_accuracy: 0.99894\n",
            "Epoch: 101, Test: Average loss: 1.0864, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 102, Train: Average loss: 0.0136, Accuracy: 100%\n",
            "epoch: 102\n",
            "train_losses: 0.013572193809747696\n",
            "train_accuracy: 0.99888\n",
            "Epoch: 102, Test: Average loss: 1.0873, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 103, Train: Average loss: 0.0138, Accuracy: 100%\n",
            "epoch: 103\n",
            "train_losses: 0.013820560401678086\n",
            "train_accuracy: 0.99908\n",
            "Epoch: 103, Test: Average loss: 1.0838, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 104, Train: Average loss: 0.0136, Accuracy: 100%\n",
            "epoch: 104\n",
            "train_losses: 0.013559972627162933\n",
            "train_accuracy: 0.999\n",
            "Epoch: 104, Test: Average loss: 1.0860, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 105, Train: Average loss: 0.0140, Accuracy: 100%\n",
            "epoch: 105\n",
            "train_losses: 0.01395165759921074\n",
            "train_accuracy: 0.99876\n",
            "Epoch: 105, Test: Average loss: 1.0815, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 106, Train: Average loss: 0.0136, Accuracy: 100%\n",
            "epoch: 106\n",
            "train_losses: 0.013586694695949555\n",
            "train_accuracy: 0.99892\n",
            "Epoch: 106, Test: Average loss: 1.0837, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 107, Train: Average loss: 0.0139, Accuracy: 100%\n",
            "epoch: 107\n",
            "train_losses: 0.01386638895392418\n",
            "train_accuracy: 0.99894\n",
            "Epoch: 107, Test: Average loss: 1.0841, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 108, Train: Average loss: 0.0140, Accuracy: 100%\n",
            "epoch: 108\n",
            "train_losses: 0.013998999395370483\n",
            "train_accuracy: 0.99902\n",
            "Epoch: 108, Test: Average loss: 1.0812, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 109, Train: Average loss: 0.0141, Accuracy: 100%\n",
            "epoch: 109\n",
            "train_losses: 0.014082410515546798\n",
            "train_accuracy: 0.99898\n",
            "Epoch: 109, Test: Average loss: 1.0842, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 110, Train: Average loss: 0.0136, Accuracy: 100%\n",
            "epoch: 110\n",
            "train_losses: 0.01358582937002182\n",
            "train_accuracy: 0.99884\n",
            "Epoch: 110, Test: Average loss: 1.0817, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 111, Train: Average loss: 0.0130, Accuracy: 100%\n",
            "epoch: 111\n",
            "train_losses: 0.012966978545188903\n",
            "train_accuracy: 0.99902\n",
            "Epoch: 111, Test: Average loss: 1.0883, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 112, Train: Average loss: 0.0137, Accuracy: 100%\n",
            "epoch: 112\n",
            "train_losses: 0.013732943161725998\n",
            "train_accuracy: 0.999\n",
            "Epoch: 112, Test: Average loss: 1.0834, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 113, Train: Average loss: 0.0137, Accuracy: 100%\n",
            "epoch: 113\n",
            "train_losses: 0.013724106945991516\n",
            "train_accuracy: 0.9989\n",
            "Epoch: 113, Test: Average loss: 1.0783, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 114, Train: Average loss: 0.0137, Accuracy: 100%\n",
            "epoch: 114\n",
            "train_losses: 0.013675084074735642\n",
            "train_accuracy: 0.99894\n",
            "Epoch: 114, Test: Average loss: 1.0837, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 115, Train: Average loss: 0.0137, Accuracy: 100%\n",
            "epoch: 115\n",
            "train_losses: 0.0136833453977108\n",
            "train_accuracy: 0.999\n",
            "Epoch: 115, Test: Average loss: 1.0831, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 116, Train: Average loss: 0.0136, Accuracy: 100%\n",
            "epoch: 116\n",
            "train_losses: 0.013620921080112458\n",
            "train_accuracy: 0.9991\n",
            "Epoch: 116, Test: Average loss: 1.0815, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 117, Train: Average loss: 0.0135, Accuracy: 100%\n",
            "epoch: 117\n",
            "train_losses: 0.013503333780765533\n",
            "train_accuracy: 0.99896\n",
            "Epoch: 117, Test: Average loss: 1.0853, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 118, Train: Average loss: 0.0136, Accuracy: 100%\n",
            "epoch: 118\n",
            "train_losses: 0.013609333790540695\n",
            "train_accuracy: 0.99898\n",
            "Epoch: 118, Test: Average loss: 1.0832, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 119, Train: Average loss: 0.0134, Accuracy: 100%\n",
            "epoch: 119\n",
            "train_losses: 0.01335163712978363\n",
            "train_accuracy: 0.99904\n",
            "Epoch: 119, Test: Average loss: 1.0835, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 120, Train: Average loss: 0.0134, Accuracy: 100%\n",
            "epoch: 120\n",
            "train_losses: 0.013358655502200127\n",
            "train_accuracy: 0.99894\n",
            "Epoch: 120, Test: Average loss: 1.0855, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 121, Train: Average loss: 0.0135, Accuracy: 100%\n",
            "epoch: 121\n",
            "train_losses: 0.013467965095043182\n",
            "train_accuracy: 0.99898\n",
            "Epoch: 121, Test: Average loss: 1.0803, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 122, Train: Average loss: 0.0135, Accuracy: 100%\n",
            "epoch: 122\n",
            "train_losses: 0.013473558602333069\n",
            "train_accuracy: 0.99902\n",
            "Epoch: 122, Test: Average loss: 1.0840, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 123, Train: Average loss: 0.0136, Accuracy: 100%\n",
            "epoch: 123\n",
            "train_losses: 0.013614705371856689\n",
            "train_accuracy: 0.99886\n",
            "Epoch: 123, Test: Average loss: 1.0803, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 124, Train: Average loss: 0.0136, Accuracy: 100%\n",
            "epoch: 124\n",
            "train_losses: 0.013625089801549911\n",
            "train_accuracy: 0.99916\n",
            "Epoch: 124, Test: Average loss: 1.0805, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 125, Train: Average loss: 0.0131, Accuracy: 100%\n",
            "epoch: 125\n",
            "train_losses: 0.01311764226436615\n",
            "train_accuracy: 0.99914\n",
            "Epoch: 125, Test: Average loss: 1.0892, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 126, Train: Average loss: 0.0133, Accuracy: 100%\n",
            "epoch: 126\n",
            "train_losses: 0.01328349584698677\n",
            "train_accuracy: 0.99898\n",
            "Epoch: 126, Test: Average loss: 1.0834, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 127, Train: Average loss: 0.0136, Accuracy: 100%\n",
            "epoch: 127\n",
            "train_losses: 0.013636368626356124\n",
            "train_accuracy: 0.99888\n",
            "Epoch: 127, Test: Average loss: 1.0840, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 128, Train: Average loss: 0.0137, Accuracy: 100%\n",
            "epoch: 128\n",
            "train_losses: 0.013694946798086166\n",
            "train_accuracy: 0.99918\n",
            "Epoch: 128, Test: Average loss: 1.0821, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 129, Train: Average loss: 0.0135, Accuracy: 100%\n",
            "epoch: 129\n",
            "train_losses: 0.013531292778253556\n",
            "train_accuracy: 0.99916\n",
            "Epoch: 129, Test: Average loss: 1.0843, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 130, Train: Average loss: 0.0139, Accuracy: 100%\n",
            "epoch: 130\n",
            "train_losses: 0.013875721901655197\n",
            "train_accuracy: 0.99894\n",
            "Epoch: 130, Test: Average loss: 1.0880, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 131, Train: Average loss: 0.0131, Accuracy: 100%\n",
            "epoch: 131\n",
            "train_losses: 0.013110311895012855\n",
            "train_accuracy: 0.99914\n",
            "Epoch: 131, Test: Average loss: 1.0860, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 132, Train: Average loss: 0.0133, Accuracy: 100%\n",
            "epoch: 132\n",
            "train_losses: 0.013312997953891754\n",
            "train_accuracy: 0.99908\n",
            "Epoch: 132, Test: Average loss: 1.0818, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 133, Train: Average loss: 0.0136, Accuracy: 100%\n",
            "epoch: 133\n",
            "train_losses: 0.013572875171899796\n",
            "train_accuracy: 0.99898\n",
            "Epoch: 133, Test: Average loss: 1.0850, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 134, Train: Average loss: 0.0130, Accuracy: 100%\n",
            "epoch: 134\n",
            "train_losses: 0.013048854883909226\n",
            "train_accuracy: 0.999\n",
            "Epoch: 134, Test: Average loss: 1.0830, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 135, Train: Average loss: 0.0132, Accuracy: 100%\n",
            "epoch: 135\n",
            "train_losses: 0.013193773030042648\n",
            "train_accuracy: 0.99916\n",
            "Epoch: 135, Test: Average loss: 1.0812, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 136, Train: Average loss: 0.0132, Accuracy: 100%\n",
            "epoch: 136\n",
            "train_losses: 0.01323274920463562\n",
            "train_accuracy: 0.99904\n",
            "Epoch: 136, Test: Average loss: 1.0858, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 137, Train: Average loss: 0.0133, Accuracy: 100%\n",
            "epoch: 137\n",
            "train_losses: 0.013258146266937255\n",
            "train_accuracy: 0.9991\n",
            "Epoch: 137, Test: Average loss: 1.0810, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 138, Train: Average loss: 0.0135, Accuracy: 100%\n",
            "epoch: 138\n",
            "train_losses: 0.013456293178796768\n",
            "train_accuracy: 0.99908\n",
            "Epoch: 138, Test: Average loss: 1.0856, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 139, Train: Average loss: 0.0131, Accuracy: 100%\n",
            "epoch: 139\n",
            "train_losses: 0.013122692852020263\n",
            "train_accuracy: 0.99906\n",
            "Epoch: 139, Test: Average loss: 1.0840, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 140, Train: Average loss: 0.0135, Accuracy: 100%\n",
            "epoch: 140\n",
            "train_losses: 0.0134635118663311\n",
            "train_accuracy: 0.99888\n",
            "Epoch: 140, Test: Average loss: 1.0829, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 141, Train: Average loss: 0.0134, Accuracy: 100%\n",
            "epoch: 141\n",
            "train_losses: 0.01339671317100525\n",
            "train_accuracy: 0.9993\n",
            "Epoch: 141, Test: Average loss: 1.0811, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 142, Train: Average loss: 0.0130, Accuracy: 100%\n",
            "epoch: 142\n",
            "train_losses: 0.01304156440973282\n",
            "train_accuracy: 0.99922\n",
            "Epoch: 142, Test: Average loss: 1.0855, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 143, Train: Average loss: 0.0133, Accuracy: 100%\n",
            "epoch: 143\n",
            "train_losses: 0.013277640725374221\n",
            "train_accuracy: 0.99898\n",
            "Epoch: 143, Test: Average loss: 1.0847, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 144, Train: Average loss: 0.0133, Accuracy: 100%\n",
            "epoch: 144\n",
            "train_losses: 0.013346817680597305\n",
            "train_accuracy: 0.99932\n",
            "Epoch: 144, Test: Average loss: 1.0805, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 145, Train: Average loss: 0.0131, Accuracy: 100%\n",
            "epoch: 145\n",
            "train_losses: 0.013066366437673569\n",
            "train_accuracy: 0.99916\n",
            "Epoch: 145, Test: Average loss: 1.0815, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 146, Train: Average loss: 0.0136, Accuracy: 100%\n",
            "epoch: 146\n",
            "train_losses: 0.013594113584756852\n",
            "train_accuracy: 0.999\n",
            "Epoch: 146, Test: Average loss: 1.0833, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 147, Train: Average loss: 0.0128, Accuracy: 100%\n",
            "epoch: 147\n",
            "train_losses: 0.012787870597839356\n",
            "train_accuracy: 0.99916\n",
            "Epoch: 147, Test: Average loss: 1.0823, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 148, Train: Average loss: 0.0135, Accuracy: 100%\n",
            "epoch: 148\n",
            "train_losses: 0.01351314264535904\n",
            "train_accuracy: 0.99908\n",
            "Epoch: 148, Test: Average loss: 1.0818, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 149, Train: Average loss: 0.0128, Accuracy: 100%\n",
            "epoch: 149\n",
            "train_losses: 0.012790635157823563\n",
            "train_accuracy: 0.99908\n",
            "Epoch: 149, Test: Average loss: 1.0817, Accuracy: 75%\n",
            "================================================================\n",
            "Epoch: 150, Train: Average loss: 0.0132, Accuracy: 100%\n",
            "epoch: 150\n",
            "train_losses: 0.01320727318763733\n",
            "train_accuracy: 0.99886\n",
            "Epoch: 150, Test: Average loss: 1.0842, Accuracy: 75%\n"
          ]
        }
      ],
      "source": [
        "dataset_name = 'cifar100'\n",
        "print(f\"Training on {dataset_name.upper()} dataset\")\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader  = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, shuffle=False, **kwargs)\n",
        "\n",
        "model = ResNet18().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "best_test_accuracy = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    adjust_learning_rate(optimizer, epoch, lr)\n",
        "\n",
        "    batch_train_loss = train(model, device, train_loader, optimizer, epoch)\n",
        "\n",
        "    print('================================================================')\n",
        "    avg_train_loss, train_accuracy = eval_model(model, device, train_loader, 'train', epoch)\n",
        "    print(\"epoch:\", epoch)\n",
        "    print(\"train_losses:\",avg_train_loss)\n",
        "    print(\"train_accuracy:\",train_accuracy)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    avg_test_loss, test_accuracy = eval_model(model, device, test_loader, 'test', epoch)\n",
        "    test_losses.append(avg_test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    if test_accuracy > best_test_accuracy:\n",
        "        best_test_accuracy = test_accuracy\n",
        "        best_epoch = epoch\n",
        "        torch.save(model.state_dict(), os.path.join(model_dir, f'model-ResNet18-{dataset_name}-best_epoch.pt'))\n",
        "        torch.save(optimizer.state_dict(), os.path.join(model_dir, f'opt-ResNet18-{dataset_name}-checkpoint_best_epoch.tar'))\n",
        "        \n",
        "torch.save(model.state_dict(), 'checkpoint_final.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=list(range(epochs)), y=train_losses, name=\"Train Loss\"))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=list(range(epochs)), y=test_losses, name=\"Test Loss\"))\n",
        "fig.update_layout(\n",
        "    title=\"Model Loss\",\n",
        "    xaxis_title=\"Epoch\",\n",
        "    yaxis_title=\"Loss\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "xVbFn5Yv2ICQ",
        "outputId": "2bf1595f-1eb0-4993-c6b6-5b452acb4278"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"b8dd4943-ddc2-4b0e-b4a2-911c901fcc71\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b8dd4943-ddc2-4b0e-b4a2-911c901fcc71\")) {                    Plotly.newPlot(                        \"b8dd4943-ddc2-4b0e-b4a2-911c901fcc71\",                        [{\"name\":\"Train Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149],\"y\":[3.9235494787597656,3.3037192343139647,3.087922897338867,2.505856487121582,2.057650827636719,1.9501251931762695,1.6270929795837403,1.4530075135803222,1.3913059776306151,1.3820694589233398,1.324376639251709,1.1666997952270508,1.1081084063720703,1.0172219400024414,1.0926812191772461,1.166377244873047,1.1056570442199707,0.9922935028839112,0.9253666529846192,0.8865671244812011,0.802580101928711,0.8144813801574707,0.7680967057800293,0.8330346383666992,0.8174067720031738,0.9349540382385254,0.666978275680542,0.7299398935699463,0.6887463056182861,0.6733204339599609,0.6808505124664307,0.747157333908081,0.7538274262237549,0.7949687300872803,0.6998581205749512,0.8439648567199707,0.8135730419921875,0.7144992852020263,0.6837767269897461,0.7575008174133301,0.6751257427978515,0.7013972143554688,0.9009980189514161,0.5710777796173095,0.6187827690124512,0.6143281429290771,0.5678191182708741,0.6960130457305909,0.7590792220306396,0.6330823832702637,0.5721790163421631,0.5823096561431885,0.5835737174987793,0.6733988120269775,0.48249601318359375,0.6155691873550415,0.629654395980835,0.5617210733795166,0.5748278903198242,0.5877965682983398,0.6374952393341065,0.6637088211059571,0.625731661529541,0.5860752397155762,0.5348027746582031,0.6225454725646973,0.6000314755249023,0.5910761717224121,0.6243263325500489,0.5847988043212891,0.6218731453704834,0.8500475196838378,0.679849298171997,0.6310613015747071,0.09642139895439147,0.06782245272636414,0.054540573930740355,0.04419198920726776,0.03823750168323517,0.03271225413322449,0.029495185420513152,0.025739228012561798,0.024032640640735625,0.02137455342888832,0.020315452498197554,0.018609578969478607,0.018144332178831102,0.01675434633731842,0.015325830154418945,0.01499543523669243,0.015143836126327515,0.014603066897392273,0.014443659760951995,0.014399568059444428,0.014798427649736405,0.014479373381137847,0.014085386010408402,0.014108391783237457,0.013869912937879562,0.013299473515748977,0.013786897710561753,0.013572193809747696,0.013820560401678086,0.013559972627162933,0.01395165759921074,0.013586694695949555,0.01386638895392418,0.013998999395370483,0.014082410515546798,0.01358582937002182,0.012966978545188903,0.013732943161725998,0.013724106945991516,0.013675084074735642,0.0136833453977108,0.013620921080112458,0.013503333780765533,0.013609333790540695,0.01335163712978363,0.013358655502200127,0.013467965095043182,0.013473558602333069,0.013614705371856689,0.013625089801549911,0.01311764226436615,0.01328349584698677,0.013636368626356124,0.013694946798086166,0.013531292778253556,0.013875721901655197,0.013110311895012855,0.013312997953891754,0.013572875171899796,0.013048854883909226,0.013193773030042648,0.01323274920463562,0.013258146266937255,0.013456293178796768,0.013122692852020263,0.0134635118663311,0.01339671317100525,0.01304156440973282,0.013277640725374221,0.013346817680597305,0.013066366437673569,0.013594113584756852,0.012787870597839356,0.01351314264535904,0.012790635157823563,0.01320727318763733],\"type\":\"scatter\"},{\"name\":\"Test Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149],\"y\":[3.919734243774414,3.332190005874634,3.1731611236572266,2.559939278793335,2.1715167411804197,2.1508018072128294,1.7840380378723144,1.6993024646759034,1.7073631927490234,1.6917100187301635,1.6707179798126222,1.5705229467391968,1.5685192710876465,1.4614761348724365,1.6002512231826782,1.685806923675537,1.6674981290817261,1.564648412513733,1.5325320266723632,1.4564186965942383,1.4351653427124023,1.4699785261154175,1.477281565093994,1.5489872581481934,1.571521469116211,1.677947327041626,1.4801998113632202,1.4983921703338623,1.4914482087135315,1.5180876739501954,1.5754692955017089,1.6244803678512574,1.6782191467285157,1.6139292922973634,1.578848314857483,1.7803343111038208,1.6941070411682129,1.7346613568305969,1.6788832988739013,1.6953853555679321,1.633165810585022,1.6908877904891968,1.8835656589508056,1.544553945541382,1.6190749269485474,1.63597599029541,1.6165169149398804,1.7193536045074462,1.8132735143661498,1.6344171871185302,1.5775261987686158,1.55041823387146,1.694363319015503,1.708089029598236,1.5054762105941772,1.6504030668258667,1.6494648246765136,1.5753047035217285,1.5886071430206299,1.684207126235962,1.716757468032837,1.7509054893493652,1.681074444580078,1.633499510192871,1.6004554176330565,1.6657267280578614,1.6511741693496704,1.66163046207428,1.7146777713775634,1.6620101259231568,1.7987641819000244,1.9014421592712403,1.7414963262557983,1.7525908306121827,1.0837077857971191,1.0652700477600097,1.0647088174819945,1.0731836500167846,1.0770649280548095,1.0791836904525758,1.0773794776916503,1.0859034938812255,1.086052092552185,1.089458994102478,1.0882442001342774,1.087939490890503,1.079947243309021,1.0868152612686157,1.0928937700271606,1.0888824110031128,1.0870586912155151,1.0869228813171388,1.0893363651275634,1.0871069305419923,1.0851456066131593,1.0876018634796143,1.0881228151321412,1.083919723701477,1.0837566743850708,1.0872260555267335,1.086394811630249,1.0873077096939088,1.0838292392730713,1.0859590314865113,1.0815093271255494,1.0836594387054443,1.0841067417144776,1.0812321458816527,1.0841569927215575,1.081690209007263,1.0883069694519043,1.0834148141860962,1.0783203178405762,1.083720002555847,1.0830922733306885,1.0815423532485962,1.085252947616577,1.083205638885498,1.083522432899475,1.0854957475662232,1.0802837852478027,1.083975880432129,1.0803236986160278,1.0805316463470458,1.0892444185256958,1.0833926267623901,1.083964186668396,1.0820500303268432,1.0842551118850707,1.0880091039657593,1.0860427766799927,1.0817660373687745,1.0849939819335936,1.083010336303711,1.081244784927368,1.0857524921417236,1.0809593423843384,1.0856417652130126,1.0839960680007934,1.0828673383712768,1.0810517559051513,1.0854826482772828,1.0846717168807984,1.0804948139190673,1.0814988279342652,1.0833468982696532,1.0822594081878663,1.081752493095398,1.0817380739212037,1.0842369611740112],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Model Loss\"},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b8dd4943-ddc2-4b0e-b4a2-911c901fcc71');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=list(range(epochs)), y=train_accuracies, name=\"Train Accuracy\"))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=list(range(epochs)), y=test_accuracies, name=\"Test Accuracy\"))\n",
        "fig.update_layout(\n",
        "    title=\"Model Accuracy\",\n",
        "    xaxis_title=\"Epoch\",\n",
        "    yaxis_title=\"Accuracy\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "O4c68uoD4-8I",
        "outputId": "5f115173-b59c-4635-9cf5-82d33d976d2c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"384d016f-13fb-4214-add9-a0ebf0e343f3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"384d016f-13fb-4214-add9-a0ebf0e343f3\")) {                    Plotly.newPlot(                        \"384d016f-13fb-4214-add9-a0ebf0e343f3\",                        [{\"name\":\"Train Accuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149],\"y\":[0.09808,0.1966,0.22922,0.34776,0.44398,0.4671,0.53636,0.58578,0.60104,0.60012,0.61172,0.65012,0.6691,0.69526,0.67316,0.66094,0.67696,0.7037,0.72364,0.73238,0.75314,0.75182,0.76506,0.7471,0.74912,0.71802,0.79208,0.77472,0.78536,0.79036,0.79042,0.77272,0.77018,0.75722,0.7827,0.74932,0.74952,0.78112,0.78846,0.7692,0.78748,0.78792,0.74002,0.82144,0.81042,0.80902,0.82382,0.78628,0.77206,0.80526,0.8231,0.81828,0.81804,0.79218,0.84774,0.81178,0.80736,0.82632,0.82496,0.82136,0.80512,0.79652,0.80884,0.81834,0.83268,0.80834,0.81474,0.8158,0.80692,0.81886,0.81068,0.7476,0.7908,0.80382,0.9764,0.98612,0.98948,0.99232,0.99378,0.99528,0.99634,0.9968,0.99668,0.99766,0.99756,0.99792,0.99806,0.99816,0.99868,0.99894,0.9987,0.99898,0.99888,0.99882,0.9988,0.99894,0.99886,0.99878,0.99896,0.999,0.99894,0.99888,0.99908,0.999,0.99876,0.99892,0.99894,0.99902,0.99898,0.99884,0.99902,0.999,0.9989,0.99894,0.999,0.9991,0.99896,0.99898,0.99904,0.99894,0.99898,0.99902,0.99886,0.99916,0.99914,0.99898,0.99888,0.99918,0.99916,0.99894,0.99914,0.99908,0.99898,0.999,0.99916,0.99904,0.9991,0.99908,0.99906,0.99888,0.9993,0.99922,0.99898,0.99932,0.99916,0.999,0.99916,0.99908,0.99908,0.99886],\"type\":\"scatter\"},{\"name\":\"Test Accuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149],\"y\":[0.1026,0.1983,0.2269,0.3429,0.4323,0.4405,0.5073,0.5336,0.5444,0.5448,0.542,0.5765,0.5765,0.6044,0.5796,0.5719,0.5753,0.5858,0.6134,0.61,0.6212,0.6168,0.6198,0.6083,0.6103,0.5825,0.6321,0.6219,0.6217,0.6231,0.6211,0.6129,0.606,0.6124,0.618,0.5948,0.5991,0.6018,0.6085,0.6041,0.6199,0.6119,0.5815,0.6346,0.6273,0.6256,0.6372,0.6048,0.595,0.6146,0.6304,0.6321,0.6136,0.6104,0.6397,0.624,0.6157,0.6328,0.6306,0.6235,0.6097,0.6103,0.618,0.6257,0.6281,0.6159,0.6177,0.6229,0.6224,0.6182,0.6062,0.5748,0.608,0.6078,0.7329,0.7377,0.7382,0.7446,0.744,0.7449,0.7452,0.7478,0.7452,0.7453,0.7448,0.7454,0.7479,0.7456,0.7458,0.7472,0.7483,0.7482,0.7465,0.7482,0.7481,0.7463,0.7478,0.7481,0.7489,0.7468,0.7467,0.7482,0.7484,0.7496,0.7485,0.7485,0.749,0.7489,0.7481,0.7489,0.7483,0.7487,0.7487,0.7486,0.7491,0.7476,0.7481,0.7477,0.7481,0.7482,0.7496,0.7506,0.7494,0.749,0.7487,0.7485,0.7501,0.7495,0.7473,0.7478,0.7493,0.7493,0.75,0.7486,0.7478,0.7498,0.749,0.749,0.7487,0.7484,0.7492,0.7488,0.7482,0.7512,0.7492,0.7479,0.747,0.7478,0.7492,0.7486],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Model Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Accuracy\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('384d016f-13fb-4214-add9-a0ebf0e343f3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/fra31/auto-attack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arF6kaTxsRWP",
        "outputId": "ca91bc7e-aeff-4df7-be80-5085960ea973"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/fra31/auto-attack\n",
            "  Cloning https://github.com/fra31/auto-attack to /tmp/pip-req-build-1ec6l1_9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/fra31/auto-attack /tmp/pip-req-build-1ec6l1_9\n",
            "  Resolved https://github.com/fra31/auto-attack to commit a39220048b3c9f2cca9a4d3a54604793c68eca7e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autoattack\n",
            "  Building wheel for autoattack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autoattack: filename=autoattack-0.1-py3-none-any.whl size=36249 sha256=4dee2641888fb620b0e14eb4dfb55765b406c91ee1c25cc17efc4d81f557379c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2vggxe4q/wheels/e5/00/6a/fb12d1eaa81d79f8c0585bdddc361ca48c9633e9549db68aef\n",
            "Successfully built autoattack\n",
            "Installing collected packages: autoattack\n",
            "Successfully installed autoattack-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoAttack - Linf"
      ],
      "metadata": {
        "id": "MqQ1epNG5h2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from autoattack import AutoAttack\n",
        "\n",
        "\n",
        "def load_model(model_path):\n",
        "    model = ResNet18()\n",
        "    ckpt = torch.load(model_path)\n",
        "    model.load_state_dict(ckpt)\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_data(data_dir):\n",
        "    transform_chain = transforms.Compose([transforms.ToTensor()])\n",
        "    item = datasets.CIFAR100(root=data_dir, train=False, transform=transform_chain, download=True)\n",
        "    test_loader = data.DataLoader(item, batch_size=1000, shuffle=False, num_workers=0)\n",
        "    return test_loader\n",
        "\n",
        "\n",
        "def create_save_dir(save_dir):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "def get_attack(model, norm, epsilon, log_path, version):\n",
        "    adversary = AutoAttack(model, norm=norm, eps=epsilon,\n",
        "                           log_path=log_path, version=version)\n",
        "    return adversary\n",
        "\n",
        "data_dir = './data'\n",
        "norm = 'Linf'\n",
        "epsilon = 8. / 255.\n",
        "model_path = '/content/model-cifar100/model-ResNet18-cifar100-best_epoch.pt'    \n",
        "n_ex = 1000\n",
        "individual = False\n",
        "save_dir = f'/content/aa-cifar100-ResNet18-Linf/AA_results_cifar100_{norm}'\n",
        "batch_size = 500\n",
        "\n",
        "version = 'standard'\n",
        "state_path = None\n",
        "\n",
        "# Settings\n",
        "parent_dir = os.path.dirname(save_dir)\n",
        "if not os.path.exists(parent_dir):\n",
        "    os.makedirs(parent_dir)\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "log_path = os.path.join(save_dir, 'log_file.txt')\n",
        "\n",
        "model = load_model(model_path)\n",
        "test_loader = load_data(data_dir)\n",
        "create_save_dir(save_dir)\n",
        "adversary = get_attack(model, norm, epsilon, log_path, version)\n",
        "\n",
        "l = [x for (x, y) in test_loader]\n",
        "x_test = torch.cat(l, 0)\n",
        "l = [y for (x, y) in test_loader]\n",
        "y_test = torch.cat(l, 0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    if not individual:\n",
        "        adv_complete = adversary.run_standard_evaluation(x_test[:n_ex], y_test[:n_ex],\n",
        "                                                          bs=batch_size, state_path=state_path)\n",
        "\n",
        "        torch.save({'adv_complete': adv_complete},\n",
        "                    f'{save_dir}/CIFAR100_Linf_aa_{version}_1_{adv_complete.shape[0]}_eps_{epsilon:.5f}.pth')\n",
        "\n",
        "    else:\n",
        "        adv_complete = adversary.run_standard_evaluation_individual(x_test[:n_ex],\n",
        "                                                                    y_test[:n_ex], bs=batch_size)\n",
        "\n",
        "        torch.save(adv_complete, f'{save_dir}/CIFAR100_Linf_aa_{version}_individual_1_{n_ex}_eps_{epsilon:.5f}.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rO1v5OviT7g",
        "outputId": "80c21277-1aac-4040-adeb-a2f8dee89434"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:12<00:00, 13082599.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "setting parameters for standard version\n",
            "using standard version including apgd-ce, apgd-t, fab-t, square.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autoattack/checks.py\", line 100, in check_dynamic\n",
            "    sys.settrace(tracefunc)\n",
            "\n",
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autoattack/checks.py\", line 102, in check_dynamic\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial accuracy: 73.60%\n",
            "apgd-ce - 1/2 - 500 out of 500 successfully perturbed\n",
            "apgd-ce - 2/2 - 236 out of 236 successfully perturbed\n",
            "robust accuracy after APGD-CE: 0.00% (total time 44.7 s)\n",
            "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoAttack - L2"
      ],
      "metadata": {
        "id": "fgQX6bhg5vjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from autoattack import AutoAttack\n",
        "\n",
        "\n",
        "def load_model(model_path):\n",
        "    model = ResNet18()\n",
        "    ckpt = torch.load(model_path)\n",
        "    model.load_state_dict(ckpt)\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_data(data_dir):\n",
        "    transform_chain = transforms.Compose([transforms.ToTensor()])\n",
        "    item = datasets.CIFAR100(root=data_dir, train=False, transform=transform_chain, download=True)\n",
        "    test_loader = data.DataLoader(item, batch_size=1000, shuffle=False, num_workers=0)\n",
        "    return test_loader\n",
        "\n",
        "\n",
        "def create_save_dir(save_dir):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "def get_attack(model, norm, epsilon, log_path, version):\n",
        "    adversary = AutoAttack(model, norm=norm, eps=epsilon,\n",
        "                           log_path=log_path, version=version)\n",
        "    return adversary\n",
        "\n",
        "data_dir = './data'\n",
        "norm = 'L2'\n",
        "epsilon = 8. / 255.\n",
        "model_path = '/content/model-cifar100/model-ResNet18-cifar100-best_epoch.pt'       \n",
        "n_ex = 1000\n",
        "individual = False\n",
        "save_dir = f'/content/aa-cifar100-ResNet18-Linf/AA_results_cifar100_{norm}'\n",
        "batch_size = 500\n",
        "\n",
        "version = 'standard'\n",
        "state_path = None\n",
        "\n",
        "# Settings\n",
        "parent_dir = os.path.dirname(save_dir)\n",
        "if not os.path.exists(parent_dir):\n",
        "    os.makedirs(parent_dir)\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "log_path = os.path.join(save_dir, 'log_file.txt')\n",
        "\n",
        "model = load_model(model_path)\n",
        "test_loader = load_data(data_dir)\n",
        "create_save_dir(save_dir)\n",
        "adversary = get_attack(model, norm, epsilon, log_path, version)\n",
        "\n",
        "l = [x for (x, y) in test_loader]\n",
        "x_test = torch.cat(l, 0)\n",
        "l = [y for (x, y) in test_loader]\n",
        "y_test = torch.cat(l, 0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    if not individual:\n",
        "        adv_complete = adversary.run_standard_evaluation(x_test[:n_ex], y_test[:n_ex],\n",
        "                                                          bs=batch_size, state_path=state_path)\n",
        "\n",
        "        torch.save({'adv_complete': adv_complete},\n",
        "                    f'{save_dir}/CIFAR100_L2_aa_{version}_1_{adv_complete.shape[0]}_eps_{epsilon:.5f}.pth')\n",
        "\n",
        "    else:\n",
        "        adv_complete = adversary.run_standard_evaluation_individual(x_test[:n_ex],\n",
        "                                                                    y_test[:n_ex], bs=batch_size)\n",
        "\n",
        "        torch.save(adv_complete, f'{save_dir}/CIFAR100_L2_aa_{version}_individual_1_{n_ex}_eps_{epsilon:.5f}.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-OpBKKvsP-g",
        "outputId": "7f0aa21f-ff63-43d6-a6e5-3d6c688dbd0e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "setting parameters for standard version\n",
            "using standard version including apgd-ce, apgd-t, fab-t, square.\n",
            "initial accuracy: 73.60%\n",
            "apgd-ce - 1/2 - 88 out of 500 successfully perturbed\n",
            "apgd-ce - 2/2 - 51 out of 236 successfully perturbed\n",
            "robust accuracy after APGD-CE: 59.70% (total time 44.1 s)\n",
            "apgd-t - 1/2 - 5 out of 500 successfully perturbed\n",
            "apgd-t - 2/2 - 0 out of 97 successfully perturbed\n",
            "robust accuracy after APGD-T: 59.20% (total time 362.4 s)\n",
            "fab-t - 1/2 - 0 out of 500 successfully perturbed\n",
            "fab-t - 2/2 - 0 out of 92 successfully perturbed\n",
            "robust accuracy after FAB-T: 59.20% (total time 937.0 s)\n",
            "square - 1/2 - 0 out of 500 successfully perturbed\n",
            "square - 2/2 - 0 out of 92 successfully perturbed\n",
            "robust accuracy after SQUARE: 59.20% (total time 1709.3 s)\n",
            "max L2 perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
            "robust accuracy: 59.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vHn8awekcExK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xOvH5xrXcC0v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}